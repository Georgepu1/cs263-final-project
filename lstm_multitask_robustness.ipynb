{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQa_KeE1krF7"
      },
      "source": [
        "Note: Get the data from the github repo: https://github.com/Georgepu1/cs263-final-project/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/LSTM')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96GXb6XNnWNR",
        "outputId": "be43f0fb-03b8-4e97-a7e9-ae56c183f311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzS-LJfRxrXX",
        "outputId": "1a8d9c7b-bf0c-48d6-b164-45cca8983e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.11.0+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchtext) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "ZUF62VszdFaa",
        "outputId": "7f95fddf-70a8-4eef-83d3-468391b08921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15390\n",
            "15390\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentences  labels\n",
              "0  The Rock is destined to be the 21st Century 's...       1\n",
              "0  Our friends won't buy this analysis, let alone...       1\n",
              "1  The gorgeously elaborate continuation of `` Th...       1\n",
              "1  One more pseudo generalization and I'm giving up.       1\n",
              "2  Singer\\/composer Bryan Adams contributes a sle...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-696eb442-a99e-4eaf-87ae-de3fe61f220f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Singer\\/composer Bryan Adams contributes a sle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-696eb442-a99e-4eaf-87ae-de3fe61f220f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-696eb442-a99e-4eaf-87ae-de3fe61f220f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-696eb442-a99e-4eaf-87ae-de3fe61f220f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Note first get the data from the github to start data prep phase\n",
        "import pandas as pd\n",
        "\n",
        "sst_tr_dataset = pd.read_csv('sst_train_data.csv')\n",
        "sst_val_dataset = pd.read_csv('sst_val_data.csv')\n",
        "sst_test_dataset = pd.read_csv('sst_test_data.csv')\n",
        "\n",
        "cola_tr_dataset = pd.read_csv('cola_train_data.csv')\n",
        "cola_val_dataset = pd.read_csv('cola_val_data.csv')\n",
        "cola_test_dataset = pd.read_csv('cola_test_data.csv')\n",
        "\n",
        "print(sst_tr_dataset.size)\n",
        "print(cola_tr_dataset.size)\n",
        "\n",
        "concat_df = pd.concat([sst_tr_dataset,cola_tr_dataset]).sort_index()\n",
        "concat_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIH06DFiscVQ"
      },
      "outputs": [],
      "source": [
        "#vocabulary = []\n",
        "#for idx, row in concat_df.iterrows():\n",
        "#    for word in row[\"sentences\"].split():\n",
        "#      if word not in vocabulary:\n",
        "#        vocabulary.append(word)\n",
        "\n",
        "#print(len(vocabulary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IUipFwAwOCO"
      },
      "outputs": [],
      "source": [
        "#print(vocabulary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stD0Sw1nCWns"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D19W47LJgJV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d46ecaf-df29-43d7-9c64-ecc79a33b593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.37MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:48<00:00, 8288.33it/s]\n"
          ]
        }
      ],
      "source": [
        "from torchtext.vocab import GloVe, vocab\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "global_vectors = GloVe(name='6B', dim=300)\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8akKpsGtlAdv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import transformers\n",
        "# from transformers import pipeline, AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig\n",
        "\n",
        "\n",
        "glove_vocab = vocab(global_vectors.stoi)\n",
        "unk_token = \"<unk>\"\n",
        "unk_index = 0\n",
        "glove_vocab.insert_token(\"<unk>\", unk_index)\n",
        "glove_vocab.set_default_index(unk_index)\n",
        "pretrained_embeddings = global_vectors.vectors\n",
        "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5-HbF5bG8qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5700fad-5ebd-4724-daa3-4d89782156bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(global_vectors.stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlkIAI8c61DU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "855a7128-083e-4a8d-88dd-fb2cef2d4e3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "        [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n",
              "        ...,\n",
              "        [ 0.0757, -0.0405,  0.1834,  ...,  0.2184,  0.3097,  0.4376],\n",
              "        [ 0.8145, -0.3622,  0.3119,  ...,  0.0755,  0.2841, -0.1756],\n",
              "        [ 0.4292, -0.2969,  0.1501,  ...,  0.2898,  0.3262, -0.0591]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "pretrained_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwHEsa0EUiaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e348919-25d0-4029-c218-9fc82691ac4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-12 02:00:48--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-06-12 02:00:48--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-06-12 02:00:48--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.09MB/s    in 2m 40s  \n",
            "\n",
            "2022-06-12 02:03:29 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvvRhAhxUiOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1152ab4a-11b7-4253-f5fc-c8d1fe64c2f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('glove.6B.300d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN-prOKoV6ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91573a3-276e-4caf-9040-be892eb6ebc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#embeddings_index[\"the\"]\n",
        "len(embeddings_index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYD-6cPLx_Nb"
      },
      "outputs": [],
      "source": [
        "# def tokenize_sentences(x, tokenizer, max_words = 48):\n",
        "#   x = tokenizer(x)\n",
        "#   if len(x) < max_words:\n",
        "#     x = x + [\"\"] * (max_words - len(x))\n",
        "#   else:\n",
        "#     x = x[:max_words]\n",
        "\n",
        "#   return glove_vocab(x)\n",
        "\n",
        "# sst_tr_dataset['sentences'] = sst_tr_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "# sst_val_dataset['sentences'] = sst_val_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "# sst_test_dataset['sentences'] = sst_test_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "# cola_tr_dataset['sentences'] = cola_tr_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "# cola_val_dataset['sentences'] = cola_val_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "# cola_test_dataset['sentences'] = cola_test_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl5_DEndP-1r"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "gen_batch_fields = ['sst_input_text', 'sst_input_inds', 'sst_target', 'cola_input_text', 'cola_input_inds', 'cola_target']\n",
        "GenBatch = namedtuple('GenBatch', field_names=gen_batch_fields, defaults=[None] * len(gen_batch_fields))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43jThE2gHzCc"
      },
      "outputs": [],
      "source": [
        "# Dataset for LSTM + Embedding / BERT\n",
        "class MultitaskDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, vocab, tokenizer, sst_X, sst_y, cola_X, cola_y, max_len=10000):\n",
        "    assert len(sst_X) == len(sst_y), \"SST data not one to one\"\n",
        "    assert len(cola_X) == len(cola_y), \"CoLA data not one to one\"\n",
        "\n",
        "    self.max_len = max_len\n",
        "    self.tokenizer = tokenizer\n",
        "    self.vocab = vocab\n",
        "    self.data = []\n",
        "    min_samples = min(len(sst_X), len(cola_X))\n",
        "    sst_X = sst_X[:min(min_samples, max_len)]\n",
        "    sst_y = sst_y[:min(min_samples, max_len)]\n",
        "    cola_X = cola_X[:min(min_samples, max_len)]\n",
        "    cola_y = cola_y[:min(min_samples, max_len)]\n",
        "    self.load_data(sst_X, sst_y, cola_X, cola_y)\n",
        "\n",
        "  def load_data(self, sst_X, sst_y, cola_X, cola_y):\n",
        "    for (cur_sst_X, cur_sst_y, cur_cola_X, cur_cola_y) in zip(sst_X, sst_y, cola_X, cola_y):\n",
        "      self.data.append({\n",
        "          'sst_input': cur_sst_X, \n",
        "          'sst_target': cur_sst_y, \n",
        "          'cola_input': cur_cola_X, \n",
        "          'cola_target': cur_cola_y,\n",
        "      })\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      # Get element consisting of sst_X, sst_y, cola_X, and cola_y\n",
        "    return self.data[index]\n",
        "\n",
        "  def tokenize_sentences(self, x, max_words=32):\n",
        "    x = self.tokenizer(x)\n",
        "    if len(x) < max_words:\n",
        "      x = x + [\"\"] * (max_words - len(x))\n",
        "    else:\n",
        "      x = x[:max_words]\n",
        "    return self.vocab(x)\n",
        "    #return [self.vocab[xi] for xi in x]\n",
        "    \n",
        "  def collate_fn(self, batch):\n",
        "    sst_input_text = [x['sst_input'] for x in batch]\n",
        "    sst_inputs = [self.tokenize_sentences(x['sst_input']) for x in batch]\n",
        "    cola_input_text = [x['cola_input'] for x in batch]\n",
        "    cola_inputs = [self.tokenize_sentences(x['cola_input']) for x in batch]\n",
        "\n",
        "    return GenBatch(\n",
        "      sst_input_text=sst_input_text,\n",
        "      sst_input_inds=sst_inputs,\n",
        "      sst_target=[x['sst_target'] for x in batch],\n",
        "      cola_input_text=cola_input_text,\n",
        "      cola_input_inds=cola_inputs,\n",
        "      cola_target=[x['cola_target'] for x in batch]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W53PhWXhHEVm"
      },
      "outputs": [],
      "source": [
        "train_set = MultitaskDataset(glove_vocab, tokenizer, sst_tr_dataset['sentences'], sst_tr_dataset['labels'], \n",
        "                             cola_tr_dataset['sentences'], cola_tr_dataset['labels'])\n",
        "val_set = MultitaskDataset(glove_vocab, tokenizer, sst_val_dataset['sentences'], sst_val_dataset['labels'], \n",
        "                           cola_val_dataset['sentences'], cola_val_dataset['labels'])\n",
        "test_set = MultitaskDataset(glove_vocab, tokenizer, sst_test_dataset['sentences'], sst_test_dataset['labels'], \n",
        "                             cola_test_dataset['sentences'], cola_test_dataset['labels'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jflla-4EIJ-9"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, shuffle=True, batch_size=8,\n",
        "                          collate_fn=train_set.collate_fn)\n",
        "val_loader  = DataLoader(val_set, shuffle=False, batch_size=8,\n",
        "                          collate_fn=val_set.collate_fn)\n",
        "test_loader  = DataLoader(test_set, shuffle=False, batch_size=8,\n",
        "                          collate_fn=test_set.collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pRpp_iYLyVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc80cf8f-7503-4f93-abcc-f3cff5af9b0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(global_vectors.stoi.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW8fNRH42EHR"
      },
      "outputs": [],
      "source": [
        "matrix_len = len(global_vectors.stoi.keys())\n",
        "weights_matrix = np.zeros((matrix_len, 300))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(global_vectors.stoi.keys()):\n",
        "    try: \n",
        "        weights_matrix[i] = embeddings_index[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(300, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy3eXeqH562R"
      },
      "outputs": [],
      "source": [
        "len(weights_matrix[1])\n",
        "weights_matrix = torch.from_numpy(weights_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VrPrbbREQP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ede6527-c7b9-49a1-ce16-35b2d64700ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400000, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "weights_matrix.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY08RL7j3XOQ"
      },
      "outputs": [],
      "source": [
        "def create_emb_layer(weights_matrix, non_trainable=False):\n",
        "    num_embeddings, embedding_dim = weights_matrix.size()\n",
        "    #num_embeddings=len(weights_matrix)\n",
        "    #embedding_dim=len(weights_matrix[1])\n",
        "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
        "    if non_trainable:\n",
        "        emb_layer.weight.requires_grad = False\n",
        "\n",
        "    return emb_layer, num_embeddings, embedding_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t7DbnBK685_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2035c08c-7d05-4a2c-963a-a878de82ad28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000 300\n"
          ]
        }
      ],
      "source": [
        "num_embeddings, embedding_dim = weights_matrix.size()\n",
        "emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
        "print(num_embeddings, embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAaEVNVEDlTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5e5460-c639-4afd-9b56-47ba79aab8cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.3227e+00, -1.4992e+00,  3.7658e-01,  ...,  8.3209e-01,\n",
              "           4.7416e-01, -1.8094e-01],\n",
              "         [-4.4425e-01, -3.7590e-01,  4.4801e-01,  ...,  2.7711e-01,\n",
              "          -1.7417e+00, -1.3152e+00],\n",
              "         [ 5.2720e-02,  4.3240e-01, -1.4621e-01,  ..., -1.7341e-01,\n",
              "          -5.8025e-01, -1.5264e-01],\n",
              "         ...,\n",
              "         [ 7.9086e-01,  4.7315e-01,  7.8253e-01,  ..., -1.1050e+00,\n",
              "          -4.8477e-01,  4.3902e-01],\n",
              "         [-7.4464e-01, -1.5717e-01,  6.4815e-02,  ..., -2.5423e-01,\n",
              "          -6.3142e-01,  5.3278e-01],\n",
              "         [ 1.0733e+00, -1.7190e+00, -1.3356e-01,  ...,  1.4763e+00,\n",
              "          -4.5795e-01, -6.4814e-01]],\n",
              "\n",
              "        [[ 2.3314e-01, -5.6579e-01, -2.3204e-01,  ..., -1.6839e+00,\n",
              "           2.2549e+00, -1.2142e+00],\n",
              "         [-2.2065e+00, -3.5880e-01,  3.7841e-01,  ..., -7.3157e-01,\n",
              "           5.7307e-01,  4.4282e-02],\n",
              "         [-2.0704e+00,  8.1091e-03, -1.2591e-01,  ...,  5.0151e-01,\n",
              "           1.6859e+00,  1.4925e+00],\n",
              "         ...,\n",
              "         [ 4.5795e-01, -9.0504e-01,  1.1578e+00,  ..., -1.3472e+00,\n",
              "           3.3240e-01, -1.6279e+00],\n",
              "         [-1.2296e+00,  1.7452e+00, -1.0816e+00,  ...,  1.3501e-01,\n",
              "          -8.9291e-01,  1.9318e-01],\n",
              "         [ 2.7319e-01, -5.7885e-01,  5.3069e-01,  ..., -6.0339e-01,\n",
              "           2.1790e+00,  9.2146e-02]],\n",
              "\n",
              "        [[-1.2677e+00,  1.4027e-01, -7.1829e-01,  ...,  3.9471e-01,\n",
              "          -3.0202e-01, -1.4251e+00],\n",
              "         [ 7.4336e-02, -1.3353e+00, -2.9716e-01,  ..., -1.3097e+00,\n",
              "           6.2279e-01,  1.3134e+00],\n",
              "         [ 6.1276e-02,  7.0722e-01,  3.3547e-01,  ...,  1.3433e+00,\n",
              "           1.5239e-01,  1.4559e+00],\n",
              "         ...,\n",
              "         [ 4.2900e-01, -9.3567e-01, -6.8599e-01,  ..., -1.4021e+00,\n",
              "           1.8636e+00,  2.0418e+00],\n",
              "         [-2.0426e+00, -2.3359e-01,  9.5709e-01,  ...,  1.8029e+00,\n",
              "          -1.5353e+00, -9.2162e-01],\n",
              "         [ 4.9738e-01, -9.2916e-01,  5.2215e-01,  ..., -1.2646e+00,\n",
              "          -3.2276e-01,  1.2387e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1.0462e+00,  1.3871e+00, -7.6401e-01,  ..., -1.0770e+00,\n",
              "          -1.0769e+00,  9.0787e-01],\n",
              "         [ 2.8402e-01, -4.9324e-01,  2.1487e+00,  ...,  1.9309e-01,\n",
              "          -1.0411e+00,  1.0678e+00],\n",
              "         [ 1.0388e+00, -1.4411e+00,  1.7438e-01,  ..., -2.3262e-01,\n",
              "          -4.9006e-01,  5.2052e-01],\n",
              "         ...,\n",
              "         [ 7.1189e-03,  1.1182e+00,  1.2761e-01,  ..., -1.4012e+00,\n",
              "          -1.1554e-03,  6.3315e-01],\n",
              "         [-1.1064e-01, -1.5938e+00,  2.9171e-01,  ..., -1.9358e-01,\n",
              "          -3.9523e-01, -1.7103e+00],\n",
              "         [-7.1910e-01,  1.3306e+00, -2.1616e-01,  ..., -3.3695e-01,\n",
              "           6.6708e-01, -1.0627e-01]],\n",
              "\n",
              "        [[-1.1593e-01, -7.3945e-01,  2.6221e-01,  ...,  1.8382e+00,\n",
              "           4.0967e-01,  2.1264e-01],\n",
              "         [ 1.6377e+00, -1.8677e+00, -2.2888e-01,  ...,  6.7080e-01,\n",
              "           1.4127e+00, -5.6971e-01],\n",
              "         [ 1.1499e+00,  4.4430e-01,  2.8053e-01,  ...,  6.2122e-02,\n",
              "          -5.0904e-01, -6.6738e-01],\n",
              "         ...,\n",
              "         [ 5.2028e-02,  8.1681e-01, -2.7707e-01,  ..., -9.7498e-02,\n",
              "          -4.8525e-01,  5.9715e-01],\n",
              "         [-2.5756e-01,  1.5772e+00, -5.2058e-01,  ..., -6.4487e-01,\n",
              "          -1.2583e-03,  7.8600e-01],\n",
              "         [-9.9534e-01,  2.3904e-01, -1.6538e-01,  ...,  1.9490e-01,\n",
              "          -5.0825e-02, -8.4202e-01]],\n",
              "\n",
              "        [[-7.2128e-01,  1.3015e+00,  1.4891e+00,  ...,  1.2938e+00,\n",
              "           1.2414e+00,  1.6115e+00],\n",
              "         [ 1.1088e+00,  1.0027e+00, -2.2522e+00,  ...,  8.4295e-01,\n",
              "          -3.7180e-01, -1.9272e+00],\n",
              "         [ 7.7925e-01,  6.0672e-01, -7.0041e-02,  ...,  3.8018e-01,\n",
              "           7.5569e-01,  7.3143e-01],\n",
              "         ...,\n",
              "         [-1.5473e-01,  8.4279e-01,  1.3363e+00,  ...,  2.6569e+00,\n",
              "           2.4733e-01, -7.1841e-01],\n",
              "         [ 1.2811e-01, -1.1291e-02,  1.8574e+00,  ..., -2.1243e-01,\n",
              "          -1.0256e+00, -3.6205e-01],\n",
              "         [-1.0024e+00, -1.1193e+00, -4.7821e-01,  ..., -1.0183e-01,\n",
              "           3.2459e-01,  3.1032e-01]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "a = torch.randint(22434,(8,32))\n",
        "#a.size()\n",
        "\n",
        "\n",
        "a[0][0]=22433\n",
        "\n",
        "\n",
        "emb_layer(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C342rTA_O8mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c7fd61-a0fc-4fe4-96bf-9fa896643644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
            "        [-0.2554, -0.2572,  0.1317,  ..., -0.2329, -0.1223,  0.3550],\n",
            "        [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368],\n",
            "        ...,\n",
            "        [ 0.0757, -0.0405,  0.1834,  ...,  0.2184,  0.3097,  0.4376],\n",
            "        [ 0.8145, -0.3622,  0.3119,  ...,  0.0755,  0.2841, -0.1756],\n",
            "        [ 0.4292, -0.2969,  0.1501,  ...,  0.2898,  0.3262, -0.0591]],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiTaskLSTM(torch.nn.Module):\n",
        "  def __init__(self, weights_matrix, emb_dim, hidden_dim):\n",
        "    super().__init__()\n",
        "    #self.embeddings = nn.EmbeddingBag.from_pretrained(pretrain_emb)\n",
        "    self.embeddings, num_embeddings, emb_dim = create_emb_layer(weights_matrix, True)\n",
        "    self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "    self.linears = nn.ModuleList([nn.Linear(hidden_dim, 2) for i in range(2)])\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.linears[0].weight.data.uniform_(-initrange, initrange)\n",
        "    self.linears[1].weight.data.uniform_(-initrange, initrange)\n",
        "    self.linears[0].bias.data.zero_()\n",
        "    self.linears[1].bias.data.zero_()\n",
        "\n",
        "  def forward(self, x, ind):\n",
        "    #print('inside forward')\n",
        "    #print(x.shape)\n",
        "    x = self.embeddings(x)\n",
        "    #print(x.shape)\n",
        "    x = self.dropout(x)\n",
        "    #print(x.shape)\n",
        "    #print('done with dropout')\n",
        "    # x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, (ht, ct) = self.lstm(x)\n",
        "    logits = self.linears[ind](ht[-1])\n",
        "\n",
        "    return F.softmax(logits, dim=-1)\n",
        "\n",
        "print(weights_matrix)\n",
        "model = MultiTaskLSTM(weights_matrix, 300, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-fFhMadv78N"
      },
      "outputs": [],
      "source": [
        "#param_groups = [{'params': model.parameters(), 'lr': 0.00001, 'weight_decay': 0.01}]\n",
        "#optimizer = AdamW(params=param_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVcSMVfby845"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "# TODO: maybe need to truncate and clip gradient\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "def eval_metrics(model, dl, criterion):\n",
        "  model.eval()\n",
        "  sst_acc = 0\n",
        "  sst_loss = 0\n",
        "  cola_acc = 0\n",
        "  cola_loss = 0\n",
        "  total = 0\n",
        "  for sample in dl:\n",
        "    model_sst_inp = torch.tensor(sample.sst_input_inds)\n",
        "    model_cola_inp = torch.tensor(sample.cola_input_inds)\n",
        "    y1_pred = model(model_sst_inp, 0).reshape(-1, 2)\n",
        "    y2_pred = model(model_cola_inp, 1).reshape(-1, 2)\n",
        "    sample_sst_target = torch.tensor(sample.sst_target).type(torch.long).reshape(-1)\n",
        "    sample_cola_target = torch.tensor(sample.cola_target).type(torch.long).reshape(-1)\n",
        "\n",
        "    sst_loss = criterion(y1_pred, sample_sst_target)\n",
        "    cola_loss = criterion(y2_pred, sample_cola_target)\n",
        "    \n",
        "    # print('Length: {}'.format(y1_pred.shape[0]))\n",
        "    sst_acc += (torch.eq(sample_sst_target,y1_pred.argmax(1))).sum().item()\n",
        "    cola_acc += (torch.eq(sample_cola_target, y2_pred.argmax(1))).sum().item()\n",
        "    sst_loss += sst_loss.item()\n",
        "    cola_loss += cola_loss.item()\n",
        "    total += y1_pred.shape[0]\n",
        "\n",
        "  return sst_acc/total, sst_loss/total, cola_acc/total, cola_loss/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT08aZRox_a7",
        "outputId": "e58e60d7-d658-4752-cc35-6d903951cc27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:45<00:00, 21.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.49889538661468485, CoLA Train accuracy: 0.6276803118908382, SST Train loss: 0.08720184368619367, CoLA Train loss: 0.08275734302360876\n",
            "SST Val accuracy: 0.530373831775701, CoLA Val accuracy: 0.7149532710280374, SST Val loss: 0.0015780782559886575, CoLA Val loss: 0.0015586630906909704 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:47<00:00, 20.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5494476933073424, CoLA Train accuracy: 0.7021442495126705, SST Train loss: 0.085783430993983, CoLA Train loss: 0.07742427472095353\n",
            "SST Val accuracy: 0.5899532710280374, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016858924645930529, CoLA Val loss: 0.0015598353929817677 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:46<00:00, 20.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5663417803768681, CoLA Train accuracy: 0.7025341130604289, SST Train loss: 0.08508497146602727, CoLA Train loss: 0.07659177316559686\n",
            "SST Val accuracy: 0.602803738317757, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016956022009253502, CoLA Val loss: 0.0015740608796477318 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:45<00:00, 21.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.580896686159844, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.08447410116883514, CoLA Train loss: 0.07635902835224417\n",
            "SST Val accuracy: 0.610981308411215, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016650903271511197, CoLA Val loss: 0.001584902172908187 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:48<00:00, 19.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5946718648473034, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.0838653332463637, CoLA Train loss: 0.07626726804730798\n",
            "SST Val accuracy: 0.6121495327102804, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.001652110368013382, CoLA Val loss: 0.0015924000181257725 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:45<00:00, 21.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.6070175438596491, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.08321054393087911, CoLA Train loss: 0.07622011635425882\n",
            "SST Val accuracy: 0.6273364485981309, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016434318386018276, CoLA Val loss: 0.0015979019226506352 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:48<00:00, 19.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.6187134502923977, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.08248776359322631, CoLA Train loss: 0.07619681954771144\n",
            "SST Val accuracy: 0.633177570093458, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016360851004719734, CoLA Val loss: 0.001602842821739614 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:48<00:00, 19.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.6337881741390513, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.08161928926372466, CoLA Train loss: 0.07617235453660183\n",
            "SST Val accuracy: 0.6647196261682243, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016607041470706463, CoLA Val loss: 0.0016068343538790941 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:45<00:00, 21.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.6471734892787524, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.08057181860736007, CoLA Train loss: 0.07615736414272341\n",
            "SST Val accuracy: 0.6810747663551402, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016491982387378812, CoLA Val loss: 0.001610399573110044 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 962/962 [00:47<00:00, 20.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.6618583495776478, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.07926615351899403, CoLA Train loss: 0.07614195687651557\n",
            "SST Val accuracy: 0.6904205607476636, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.0016052982537075877, CoLA Val loss: 0.0016141962260007858 \n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "epochs = 10\n",
        "\n",
        "# offset input is required due to how embeddings are loaded in\n",
        "#offset_input = torch.tensor([0])\n",
        "\n",
        "for _ in range(epochs):\n",
        "  \n",
        "  tr_count = 0\n",
        "  sst_tr_acc = 0\n",
        "  sst_tr_loss = 0\n",
        "  cola_tr_acc = 0\n",
        "  cola_tr_loss = 0\n",
        "  for sample in tqdm(train_loader):\n",
        "    # Note can also set the data to a decide (cuda)\n",
        "    model.zero_grad()\n",
        "    # print(type(sample.sst_input_inds))\n",
        "    # print(torch.tensor(sample.sst_input_inds))\n",
        "    # print(torch.tensor(sample.sst_input_inds).type(torch.long))\n",
        "    model_sst_inp = torch.tensor(sample.sst_input_inds)\n",
        "    #print(model_sst_inp)\n",
        "    model_cola_inp = torch.tensor(sample.cola_input_inds)\n",
        "    #print(model_cola_inp.shape)\n",
        "    y1_pred = model(model_sst_inp, 0).reshape(-1, 2)\n",
        "    y2_pred = model(model_cola_inp, 1).reshape(-1, 2)\n",
        "    sample_sst_target = torch.tensor(sample.sst_target).type(torch.long).reshape(-1)\n",
        "    sample_cola_target = torch.tensor(sample.cola_target).type(torch.long).reshape(-1)\n",
        "    #print(y1_pred.shape)\n",
        "    #print(sample_sst_target.shape)\n",
        "    sst_loss = criterion(y1_pred, sample_sst_target)\n",
        "    cola_loss = criterion(y2_pred, sample_cola_target)\n",
        "    # multitask loss\n",
        "    loss = sst_loss + cola_loss\n",
        "    loss.backward()\n",
        "\n",
        "    # intermediate variabels stores embedding of x and computes\n",
        "    # m_output.grad w.r.t. this and calculate the MSE of the m_output.grad(emb_x)\n",
        "    # norm and 1.0 and use relu on; before you do the square, pass it through a relu\n",
        "    # so everything les than 1.0 wont be counted to the square.\n",
        "    # MSE (m_output.grad(x), 1.0) calulate gradient of M output w.r.t. x's embedding space\n",
        "    # To avoid overfitting, calculating regularization term can use a varied version of x\n",
        "    # instead of the original (e.g. add gaussian noise around embeddings of x); can\n",
        "    # also minimize discrepancy on the two for robustness of model\n",
        "    # Lipschitz-regularized loss\n",
        "    optimizer.step()\n",
        "    sst_tr_acc += (torch.eq(sample_sst_target,y1_pred.argmax(1))).sum().item()\n",
        "    cola_tr_acc += (torch.eq(sample_cola_target, y2_pred.argmax(1))).sum().item()\n",
        "    sst_tr_loss += sst_loss.item()\n",
        "    cola_tr_loss += cola_loss.item()\n",
        "    tr_count += y1_pred.shape[0]\n",
        "    \n",
        "  print(\"SST Train accuracy: {}, CoLA Train accuracy: {}, SST Train loss: {}, CoLA Train loss: {}\".format(sst_tr_acc/tr_count, cola_tr_acc/tr_count, sst_tr_loss/tr_count, cola_tr_loss/tr_count))\n",
        "  val_sst_acc, val_sst_loss, val_cola_acc, val_cola_loss = eval_metrics(model, val_loader, criterion)\n",
        "  print(\"SST Val accuracy: {}, CoLA Val accuracy: {}, SST Val loss: {}, CoLA Val loss: {} \".format(val_sst_acc, val_cola_acc, val_sst_loss, val_cola_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeT2uQEIhS8n",
        "outputId": "0c202d31-9eb1-4091-b9a4-23fee376fddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Test accuracy: 0.7115749525616698, CoLA Val accuracy: 0.6925996204933587, SST Val loss: 0.0020207613706588745, CoLA Val loss: 0.0032476233318448067 \n"
          ]
        }
      ],
      "source": [
        "test_sst_acc, test_sst_loss, test_cola_acc, test_cola_loss = eval_metrics(model, test_loader, criterion)\n",
        "print(\"SST Test accuracy: {}, CoLA Val accuracy: {}, SST Val loss: {}, CoLA Val loss: {} \".format(test_sst_acc, test_cola_acc, test_sst_loss, test_cola_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlCTcEOOSgcV"
      },
      "source": [
        "### TODO: Adversarial attacks and Robustness Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLH_bFIASkWE"
      },
      "outputs": [],
      "source": [
        "def attack():\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "sst_adv_dataset = pd.read_csv('adversial_sst.csv')\n",
        "cola_adv_dataset = pd.read_csv('adversial_cola.csv')"
      ],
      "metadata": {
        "id": "wtT3Kp_Z-Q02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_set = MultitaskDataset(glove_vocab, tokenizer, sst_adv_dataset['sentences'], sst_adv_dataset['labels'], cola_adv_dataset['sentences'], cola_adv_dataset['labels'])\n",
        "adv_loader=DataLoader(adv_set, shuffle=False, batch_size=8, collate_fn=adv_set.collate_fn)"
      ],
      "metadata": {
        "id": "T5LJ1qRE-RqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Rzr_ap3D9p",
        "outputId": "4bdabc06-f9c4-437f-c15f-36d07f6702f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adv_sst_acc, adv_sst_loss, adv_cola_acc, adv_cola_loss = eval_metrics(model, adv_loader, criterion)\n",
        "print(\"SST ADV accuracy: {}, CoLA ADV accuracy: {}, SST ADV loss: {}, CoLA ADV loss: {} \".format(test_sst_acc, test_cola_acc, test_sst_loss, test_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_-PZfy0-XDY",
        "outputId": "84be1450-c2f9-476d-ce3e-39d7be08b059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST ADV accuracy: 0.6425233644859814, CoLA ADV accuracy: 0.719626168224299, SST ADV loss: 0.0016325060278177261, CoLA ADV loss: 0.0015612159622833133 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT transfer attacks\n",
        "\n",
        "sst_adv_dataset = pd.read_csv('bert_adversarial_sst.csv')\n",
        "cola_adv_dataset = pd.read_csv('bert_adversarial_cola.csv')\n",
        "\n",
        "adv_set = MultitaskDataset(glove_vocab, tokenizer, sst_adv_dataset['sentences'], sst_adv_dataset['labels'], cola_adv_dataset['sentences'], cola_adv_dataset['labels'])\n",
        "adv_loader  = DataLoader(adv_set, shuffle=False, batch_size=8, collate_fn=adv_set.collate_fn)\n"
      ],
      "metadata": {
        "id": "pZR2uvTjvP7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_sst_acc, adv_sst_loss, adv_cola_acc, adv_cola_loss = eval_metrics(model, adv_loader, criterion)\n",
        "print(\"SST ADV accuracy: {}, CoLA ADV accuracy: {}, SST ADV loss: {}, CoLA ADV loss: {} \".format(adv_sst_acc, adv_cola_acc, adv_sst_loss, adv_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o--m5jZ6v8CY",
        "outputId": "a9e0d579-d4e7-47d7-f0d7-a637b4eb12f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST ADV accuracy: 0.5847457627118644, CoLA ADV accuracy: 0.8491525423728814, SST ADV loss: 0.002424434293061495, CoLA ADV loss: 0.001985773677006364 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROBERTA transfer attack\n",
        "\n",
        "sst_adv_dataset = pd.read_csv('roberta_adversarial_sst.csv')\n",
        "cola_adv_dataset = pd.read_csv('roberta_adversarial_cola.csv')\n",
        "\n",
        "adv_set = MultitaskDataset(glove_vocab, tokenizer, sst_adv_dataset['sentences'], sst_adv_dataset['labels'], \n",
        "                             cola_adv_dataset['sentences'], cola_adv_dataset['labels'])\n",
        "adv_loader  = DataLoader(adv_set, shuffle=False, batch_size=8,\n",
        "                          collate_fn=adv_set.collate_fn)"
      ],
      "metadata": {
        "id": "IIoXp1UiwE2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_sst_acc, adv_sst_loss, adv_cola_acc, adv_cola_loss = eval_metrics(model, adv_loader, criterion)\n",
        "print(\"SST ADV accuracy: {}, CoLA ADV accuracy: {}, SST ADV loss: {}, CoLA ADV loss: {} \".format(adv_sst_acc, adv_cola_acc, adv_sst_loss, adv_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju54NwGfwF_M",
        "outputId": "186f601d-cf0d-461c-b861-2a5ae05b4b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST ADV accuracy: 0.5428571428571428, CoLA ADV accuracy: 0.8767857142857143, SST ADV loss: 0.0023840838111937046, CoLA ADV loss: 0.002176337642595172 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data aug\n",
        "sst_adv_dataset = pd.read_csv('augmented_sst.csv')\n",
        "cola_adv_dataset = pd.read_csv('augmented_cola.csv')\n",
        "\n",
        "adv_set = MultitaskDataset(glove_vocab, tokenizer, sst_adv_dataset['sentences'], sst_adv_dataset['labels'], \n",
        "                             cola_adv_dataset['sentences'], cola_adv_dataset['labels'])\n",
        "adv_loader  = DataLoader(adv_set, shuffle=False, batch_size=8,\n",
        "                          collate_fn=adv_set.collate_fn)\n"
      ],
      "metadata": {
        "id": "elTFCpnZwN83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4E2NXzwsz_WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48875d8a-da20-431d-a8b4-37d701f9ff25",
        "id": "yNdzRq-m5_N0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:06<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5125, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.08805537905011858, CoLA Train loss: 0.0577633263277156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 20.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5446428571428571, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.0868006210241999, CoLA Train loss: 0.05725222038371222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 21.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5553571428571429, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.0863548815782581, CoLA Train loss: 0.0568770418209689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 21.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5660714285714286, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.08602850559566702, CoLA Train loss: 0.056591811616505894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 20.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5732142857142857, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.08577138744294643, CoLA Train loss: 0.05636674591473171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 20.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5732142857142857, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.0855578959520374, CoLA Train loss: 0.05618421525827476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 19.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5732142857142857, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.08537357167473861, CoLA Train loss: 0.05603300540574959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 19.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5803571428571429, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.08520969748497009, CoLA Train loss: 0.055905591802937644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 19.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5821428571428572, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.08506073914468289, CoLA Train loss: 0.05579671795879092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [00:03<00:00, 20.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5839285714285715, CoLA Train accuracy: 0.8767857142857143, SST Train loss: 0.0849229957908392, CoLA Train loss: 0.05570258939904826\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "epochs = 10\n",
        "\n",
        "# offset input is required due to how embeddings are loaded in\n",
        "#offset_input = torch.tensor([0])\n",
        "\n",
        "for _ in range(epochs):\n",
        "  \n",
        "  tr_count = 0\n",
        "  sst_tr_acc = 0\n",
        "  sst_tr_loss = 0\n",
        "  cola_tr_acc = 0\n",
        "  cola_tr_loss = 0\n",
        "  for sample in tqdm(adv_loader):\n",
        "    # Note can also set the data to a decide (cuda)\n",
        "    model.zero_grad()\n",
        "\n",
        "    model_sst_inp = torch.tensor(sample.sst_input_inds)\n",
        "    model_cola_inp = torch.tensor(sample.cola_input_inds)\n",
        "\n",
        "    y1_pred = model(model_sst_inp, 0).reshape(-1, 2)\n",
        "    y2_pred = model(model_cola_inp, 1).reshape(-1, 2)\n",
        "    sample_sst_target = torch.tensor(sample.sst_target).type(torch.long).reshape(-1)\n",
        "    sample_cola_target = torch.tensor(sample.cola_target).type(torch.long).reshape(-1)\n",
        "\n",
        "    sst_loss = criterion(y1_pred, sample_sst_target)\n",
        "    cola_loss = criterion(y2_pred, sample_cola_target)\n",
        "    # multitask loss\n",
        "    loss = sst_loss + cola_loss\n",
        "    loss.backward()\n",
        "\n",
        "    # intermediate variabels stores embedding of x and computes\n",
        "    # m_output.grad w.r.t. this and calculate the MSE of the m_output.grad(emb_x)\n",
        "    # norm and 1.0 and use relu on; before you do the square, pass it through a relu\n",
        "    # so everything les than 1.0 wont be counted to the square.\n",
        "    # MSE (m_output.grad(x), 1.0) calulate gradient of M output w.r.t. x's embedding space\n",
        "    # To avoid overfitting, calculating regularization term can use a varied version of x\n",
        "    # instead of the original (e.g. add gaussian noise around embeddings of x); can\n",
        "    # also minimize discrepancy on the two for robustness of model\n",
        "    # Lipschitz-regularized loss\n",
        "    optimizer.step()\n",
        "    sst_tr_acc += (torch.eq(sample_sst_target,y1_pred.argmax(1))).sum().item()\n",
        "    cola_tr_acc += (torch.eq(sample_cola_target, y2_pred.argmax(1))).sum().item()\n",
        "    sst_tr_loss += sst_loss.item()\n",
        "    cola_tr_loss += cola_loss.item()\n",
        "    tr_count += y1_pred.shape[0]\n",
        "    \n",
        "  print(\"SST Train accuracy: {}, CoLA Train accuracy: {}, SST Train loss: {}, CoLA Train loss: {}\".format(sst_tr_acc/tr_count, cola_tr_acc/tr_count, sst_tr_loss/tr_count, cola_tr_loss/tr_count))\n",
        "  val_sst_acc, val_sst_loss, val_cola_acc, val_cola_loss = eval_metrics(model, val_loader, criterion)\n",
        "  #print(\"SST Val accuracy: {}, CoLA Val accuracy: {}, SST Val loss: {}, CoLA Val loss: {} \".format(val_sst_acc, val_cola_acc, val_sst_loss, val_cola_loss))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sst_acc, test_sst_loss, test_cola_acc, test_cola_loss = eval_metrics(model, test_loader, criterion)\n",
        "print(\"SST Test accuracy: {}, CoLA Val accuracy: {}, SST Val loss: {}, CoLA Val loss: {} \".format(test_sst_acc, test_cola_acc, test_sst_loss, test_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVXLEhnF7v_b",
        "outputId": "5913d995-8874-435b-ee26-b60e0f35685c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Test accuracy: 0.8444022770398482, CoLA Val accuracy: 0.6925996204933587, SST Val loss: 0.0016692557837814093, CoLA Val loss: 0.003322326811030507 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT transfer attacks\n",
        "\n",
        "sst_adv_dataset = pd.read_csv('bert_adversarial_sst.csv')\n",
        "cola_adv_dataset = pd.read_csv('bert_adversarial_cola.csv')\n",
        "\n",
        "adv_set = MultitaskDataset(glove_vocab, tokenizer, sst_adv_dataset['sentences'], sst_adv_dataset['labels'], \n",
        "                             cola_adv_dataset['sentences'], cola_adv_dataset['labels'])\n",
        "adv_loader  = DataLoader(adv_set, shuffle=False, batch_size=8,\n",
        "                          collate_fn=adv_set.collate_fn)\n"
      ],
      "metadata": {
        "id": "8EiEkLzWwUPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_sst_acc, adv_sst_loss, adv_cola_acc, adv_cola_loss = eval_metrics(model, adv_loader, criterion)\n",
        "print(\"SST ADV accuracy: {}, CoLA ADV accuracy: {}, SST ADV loss: {}, CoLA ADV loss: {} \".format(adv_sst_acc, adv_cola_acc, adv_sst_loss, adv_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOYT9XXrwWLu",
        "outputId": "3141f8d0-46a6-4d3a-832c-e2c18d9bc9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST ADV accuracy: 0.6338983050847458, CoLA ADV accuracy: 0.8491525423728814, SST ADV loss: 0.002810135018080473, CoLA ADV loss: 0.002096907002851367 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROBERTA transfer attack\n",
        "\n",
        "sst_adv_dataset = pd.read_csv('roberta_adversarial_sst.csv')\n",
        "cola_adv_dataset = pd.read_csv('roberta_adversarial_cola.csv')\n",
        "\n",
        "adv_set = MultitaskDataset(glove_vocab, tokenizer, sst_adv_dataset['sentences'], sst_adv_dataset['labels'], \n",
        "                             cola_adv_dataset['sentences'], cola_adv_dataset['labels'])\n",
        "adv_loader  = DataLoader(adv_set, shuffle=False, batch_size=8,\n",
        "                          collate_fn=adv_set.collate_fn)\n"
      ],
      "metadata": {
        "id": "wMVPPpiywaeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adv_sst_acc, adv_sst_loss, adv_cola_acc, adv_cola_loss = eval_metrics(model, adv_loader, criterion)\n",
        "print(\"SST ADV accuracy: {}, CoLA ADV accuracy: {}, SST ADV loss: {}, CoLA ADV loss: {} \".format(adv_sst_acc, adv_cola_acc, adv_sst_loss, adv_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSU4Zc1VwePd",
        "outputId": "c046a869-faa5-46ff-8da3-7dd911fb1ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST ADV accuracy: 0.6035714285714285, CoLA ADV accuracy: 0.8767857142857143, SST ADV loss: 0.002722404198721051, CoLA ADV loss: 0.0020665836054831743 \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Final_lstm_multitask_robustness",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}