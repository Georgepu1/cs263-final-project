{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_multitask_robustness",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzS-LJfRxrXX",
        "outputId": "b96430eb-a881-4af4-a711-e583753eb9e7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchtext) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note first get the data from the github to start data prep phase\n",
        "import pandas as pd\n",
        "\n",
        "sst_tr_dataset = pd.read_csv('sst_train_data.csv')\n",
        "sst_val_dataset = pd.read_csv('sst_val_data.csv')\n",
        "sst_test_dataset = pd.read_csv('sst_test_data.csv')\n",
        "\n",
        "cola_tr_dataset = pd.read_csv('cola_train_data.csv')\n",
        "cola_val_dataset = pd.read_csv('cola_val_data.csv')\n",
        "cola_test_dataset = pd.read_csv('cola_test_data.csv')\n",
        "\n",
        "sst_tr_dataset.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZUF62VszdFaa",
        "outputId": "5648ea35-e4e2-4f17-8cba-7ab62e675403"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentences  labels\n",
              "3847  In his latest effort , Storytelling , Solondz ...       1\n",
              "3264  Boasts a handful of virtuosic set pieces and o...       1\n",
              "2421  The leanest and meanest of Solondz 's misanthr...       1\n",
              "1896                              This is SO De Palma .       1\n",
              "7202  For every articulate player , such as skateboa...       0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c7666ac-bc07-4ae8-8620-9d3e05ccc4f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3847</th>\n",
              "      <td>In his latest effort , Storytelling , Solondz ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>Boasts a handful of virtuosic set pieces and o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2421</th>\n",
              "      <td>The leanest and meanest of Solondz 's misanthr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>This is SO De Palma .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7202</th>\n",
              "      <td>For every articulate player , such as skateboa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c7666ac-bc07-4ae8-8620-9d3e05ccc4f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c7666ac-bc07-4ae8-8620-9d3e05ccc4f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c7666ac-bc07-4ae8-8620-9d3e05ccc4f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import GloVe, vocab\n",
        "global_vectors = GloVe(name='6B', dim=300)"
      ],
      "metadata": {
        "id": "D19W47LJgJV3"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import transformers\n",
        "from transformers import pipeline, AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig\n",
        "from transformers import AutoConfig, AutoModelForPreTraining\n",
        "from transformers import AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from collections import namedtuple\n",
        "\n",
        "\n",
        "glove_vocab = vocab(global_vectors.stoi)\n",
        "unk_token = \"<unk>\"\n",
        "unk_index = 0\n",
        "glove_vocab.insert_token(\"<unk>\", unk_index)\n",
        "glove_vocab.set_default_index(unk_index)\n",
        "pretrained_embeddings = global_vectors.vectors\n",
        "pretrained_embeddings = torch.cat((torch.zeros(1,pretrained_embeddings.shape[1]),pretrained_embeddings))"
      ],
      "metadata": {
        "id": "8akKpsGtlAdv"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_words = 48\n",
        "\n",
        "# test = tokenizer(sst_tr_dataset['sentences'][0])\n",
        "# test = test + [\"\"] * (max_words - len(test))\n",
        "# glove_vocab(test)"
      ],
      "metadata": {
        "id": "0UugWLVjWBFC"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentences(x, tokenizer, max_words = 48):\n",
        "  x = tokenizer(x)\n",
        "  if len(x) < max_words:\n",
        "    x = x + [\"\"] * (max_words - len(x))\n",
        "  else:\n",
        "    x = x[:max_words]\n",
        "\n",
        "  return glove_vocab(x)\n",
        "\n",
        "sst_tr_dataset['sentences'] = sst_tr_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "sst_val_dataset['sentences'] = sst_val_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "sst_test_dataset['sentences'] = sst_test_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "cola_tr_dataset['sentences'] = cola_tr_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "cola_val_dataset['sentences'] = cola_val_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n",
        "cola_test_dataset['sentences'] = cola_test_dataset['sentences'].apply(lambda x: tokenize_sentences(x, tokenizer))\n"
      ],
      "metadata": {
        "id": "SYD-6cPLx_Nb"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset for LSTM + Embedding / BERT\n",
        "class MultitaskDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, sst_X, sst_y, cola_X, cola_y, max_len=10000):\n",
        "    assert len(sst_X) == len(sst_y), \"SST data not one to one\"\n",
        "    assert len(cola_X) == len(cola_y), \"CoLA data not one to one\"\n",
        "\n",
        "    self.max_len = max_len\n",
        "\n",
        "    min_samples = min(len(sst_X), len(cola_X))\n",
        "    sst_X = sst_X[:min(min_samples, max_len)]\n",
        "    sst_y = sst_y[:min(min_samples, max_len)]\n",
        "    cola_X = cola_X[:min(min_samples, max_len)]\n",
        "    cola_y = cola_y[:min(min_samples, max_len)]\n",
        "\n",
        "    self.sst_X = sst_X\n",
        "    self.sst_y = sst_y\n",
        "    self.cola_X = cola_X\n",
        "    self.cola_y = cola_y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sst_X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      # Get element consisting of sst_X, sst_y, cola_X, and cola_y\n",
        "    return (self.sst_X[index], self.sst_y[index], self.cola_X[index], self.cola_y[index])"
      ],
      "metadata": {
        "id": "43jThE2gHzCc"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = MultitaskDataset(sst_tr_dataset['sentences'], sst_tr_dataset['labels'], \n",
        "                             cola_tr_dataset['sentences'], cola_tr_dataset['labels'])\n",
        "val_set = MultitaskDataset(sst_val_dataset['sentences'], sst_val_dataset['labels'], \n",
        "                           cola_val_dataset['sentences'], cola_val_dataset['labels'])\n",
        "test_set = MultitaskDataset(sst_test_dataset['sentences'], sst_test_dataset['labels'], \n",
        "                             cola_test_dataset['sentences'], cola_test_dataset['labels'])"
      ],
      "metadata": {
        "id": "W53PhWXhHEVm"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, shuffle=True)\n",
        "val_loader  = DataLoader(val_set, shuffle=False)\n",
        "test_loader  = DataLoader(test_set, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Jflla-4EIJ-9"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiTaskLSTM(torch.nn.Module):\n",
        "  def __init__(self, pretrain_emb, emb_dim, hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embeddings = nn.EmbeddingBag.from_pretrained(pretrain_emb)\n",
        "    self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "    self.linears = nn.ModuleList([nn.Linear(hidden_dim, 1) for i in range(2)])\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    initrange = 0.5\n",
        "    self.linears[0].weight.data.uniform_(-initrange, initrange)\n",
        "    self.linears[1].weight.data.uniform_(-initrange, initrange)\n",
        "    self.linears[0].bias.data.zero_()\n",
        "    self.linears[1].bias.data.zero_()\n",
        "\n",
        "  def forward(self, x, ind, offset):\n",
        "    x = self.embeddings(x, offset)\n",
        "    x = self.dropout(x)\n",
        "    # x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
        "    lstm_out, (ht, ct) = self.lstm(x)\n",
        "    return torch.sigmoid(self.linears[ind](ht[-1]))\n",
        "\n",
        "model = MultiTaskLSTM(pretrained_embeddings, 300, 64)"
      ],
      "metadata": {
        "id": "C342rTA_O8mL"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-4\n",
        "criterion = nn.BCELoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "offset_input = torch.tensor([0])\n"
      ],
      "metadata": {
        "id": "XVcSMVfby845"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metrics(model, dl, criterion):\n",
        "  model.eval()\n",
        "  sst_acc = 0\n",
        "  sst_loss = 0\n",
        "  cola_acc = 0\n",
        "  cola_loss = 0\n",
        "  total = 0\n",
        "\n",
        "  for (x1, y1, x2, y2) in dl:\n",
        "    # Note can also set the data to a decide (cuda)\n",
        "    x1 = torch.LongTensor(x1)\n",
        "    x2 = torch.LongTensor(x2)\n",
        "    y1 = y1.type(torch.float)\n",
        "    y2 = y2.type(torch.float)\n",
        "    y1_pred = model(x1, 0, offset_input)\n",
        "    y2_pred = model(x2, 1, offset_input)\n",
        "    sst_loss = criterion(y1_pred, y1)\n",
        "    cola_loss = criterion(y2_pred, y2)\n",
        "    # multitask loss\n",
        "    loss = sst_loss + cola_loss\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    sst_acc += (round(y1_pred.item()) == y1.item())\n",
        "    cola_acc += (round(y2_pred.item()) == y2.item())\n",
        "    sst_loss += sst_loss.item()\n",
        "    cola_loss += cola_loss.item()\n",
        "    total += 1\n",
        "\n",
        "  return sst_acc/total, sst_loss/total, cola_acc/total, cola_loss/total"
      ],
      "metadata": {
        "id": "2wJQtiQ6x_T5"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "epochs = 10\n",
        "\n",
        "for _ in range(epochs):\n",
        "  \n",
        "  tr_count = 0\n",
        "  sst_tr_acc = 0\n",
        "  sst_tr_loss = 0\n",
        "  cola_tr_acc = 0\n",
        "  cola_tr_loss = 0\n",
        "  for (x1, y1, x2, y2) in tqdm(train_loader):\n",
        "    # Note can also set the data to a decide (cuda)\n",
        "    model.zero_grad()\n",
        "    \n",
        "    x1 = torch.LongTensor(x1)\n",
        "    x2 = torch.LongTensor(x2)\n",
        "    y1 = y1.type(torch.float)\n",
        "    y2 = y2.type(torch.float)\n",
        "    y1_pred = model(x1, 0, offset_input)\n",
        "    y2_pred = model(x2, 1, offset_input)\n",
        "    sst_loss = criterion(y1_pred, y1)\n",
        "    cola_loss = criterion(y2_pred, y2)\n",
        "    # multitask loss\n",
        "    loss = sst_loss + cola_loss\n",
        "    loss.backward()\n",
        "    # intermediate variabels stores embedding of x and computes\n",
        "    # m_output.grad w.r.t. this and calculate the MSE of the m_output.grad(emb_x)\n",
        "    # norm and 1.0 and use relu on; before you do the square, pass it through a relu\n",
        "    # so everything les than 1.0 wont be counted to the square.\n",
        "    # MSE (m_output.grad(x), 1.0) calulate gradient of M output w.r.t. x's embedding space\n",
        "    # To avoid overfitting, calculating regularization term can use a varied version of x\n",
        "    # instead of the original (e.g. add gaussian noise around embeddings of x); can\n",
        "    # also minimize discrepancy on the two for robustness of model\n",
        "    # Lipschitz-regularized loss\n",
        "    optimizer.step()\n",
        "    sst_tr_acc += (round(y1_pred.item()) == y1.item())\n",
        "    cola_tr_acc += (round(y2_pred.item()) == y2.item())\n",
        "    sst_tr_loss += sst_loss.item()\n",
        "    cola_tr_loss += cola_loss.item()\n",
        "    tr_count += 1\n",
        "    \n",
        "  print(\"SST Train accuracy: {}, CoLA Train accuracy: {}, SST Train loss: {}, CoLA Train loss: {}\".format(sst_tr_acc/tr_count, cola_tr_acc/tr_count, sst_tr_loss/tr_count, cola_tr_loss/tr_count))\n",
        "  val_sst_acc, val_sst_loss, val_cola_acc, val_cola_loss = eval_metrics(model, val_loader, criterion)\n",
        "  print(\"SST Val accuracy: {}, CoLA Val accuracy: {}, SST Val loss: {}, CoLA Val loss: {} \".format(val_sst_acc, val_cola_acc, val_sst_loss, val_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT08aZRox_a7",
        "outputId": "2aea36f7-24d2-405c-8a65-461e94e20c3f"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [01:02<00:00, 122.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 0.6909473202226997, CoLA Train loss: 0.6087731322930803\n",
            "SST Val accuracy: 0.8002336448598131, CoLA Val accuracy: 0.6740654205607477, SST Val loss: 9.163697001213222e-08, CoLA Val loss: 0.0003434980462770909 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:36<00:00, 212.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.46835607537361923, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 4.020406118157929, CoLA Train loss: 0.6594015607902026\n",
            "SST Val accuracy: 0.5467289719626168, CoLA Val accuracy: 0.719626168224299, SST Val loss: 1.462268084395646e-08, CoLA Val loss: 0.0008913925266824663 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:38<00:00, 200.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.46835607537361923, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 4.076741085710828, CoLA Train loss: 0.609083831612362\n",
            "SST Val accuracy: 0.5163551401869159, CoLA Val accuracy: 0.6647196261682243, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.00032364667276851833 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:35<00:00, 214.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 46.83560753736192, CoLA Train loss: 0.6717794362990557\n",
            "SST Val accuracy: 0.6063084112149533, CoLA Val accuracy: 0.719626168224299, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.0005660622846335173 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:36<00:00, 212.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 46.83560753736192, CoLA Train loss: 0.6200647887256411\n",
            "SST Val accuracy: 0.6063084112149533, CoLA Val accuracy: 0.6845794392523364, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.0006787392776459455 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:38<00:00, 201.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 46.83560753736192, CoLA Train loss: 0.6121031098895603\n",
            "SST Val accuracy: 0.6063084112149533, CoLA Val accuracy: 0.6682242990654206, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.000813046470284462 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:36<00:00, 212.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 46.83560753736192, CoLA Train loss: 0.6087891669572368\n",
            "SST Val accuracy: 0.6063084112149533, CoLA Val accuracy: 0.6647196261682243, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.0009991888655349612 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:36<00:00, 211.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 46.83560753736192, CoLA Train loss: 0.6120928503500324\n",
            "SST Val accuracy: 0.6063084112149533, CoLA Val accuracy: 0.6448598130841121, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.0011887570144608617 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:36<00:00, 210.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 46.83560753736192, CoLA Train loss: 0.6220966569861474\n",
            "SST Val accuracy: 0.6063084112149533, CoLA Val accuracy: 0.6343457943925234, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.0013979682698845863 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7695/7695 [00:36<00:00, 212.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Train accuracy: 0.5316439246263808, CoLA Train accuracy: 0.7026640675763483, SST Train loss: 46.83560753736192, CoLA Train loss: 0.6380222904132201\n",
            "SST Val accuracy: 0.6063084112149533, CoLA Val accuracy: 0.6273364485981309, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.0016023971838876605 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sst_acc, test_sst_loss, test_cola_acc, test_cola_loss = eval_metrics(model, val_loader, criterion)\n",
        "print(\"SST Test accuracy: {}, CoLA Val accuracy: {}, SST Val loss: {}, CoLA Val loss: {} \".format(test_sst_acc, test_cola_acc, test_sst_loss, test_cola_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeT2uQEIhS8n",
        "outputId": "68fec03a-3579-47f7-99f0-bc06ba075146"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SST Test accuracy: 0.6063084112149533, CoLA Val accuracy: 0.6273364485981309, SST Val loss: 0.23364485800266266, CoLA Val loss: 0.0034176348708570004 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO: Adversarial attacks and Robustness Evaluation"
      ],
      "metadata": {
        "id": "NlCTcEOOSgcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attack():\n",
        "  pass"
      ],
      "metadata": {
        "id": "fLH_bFIASkWE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}